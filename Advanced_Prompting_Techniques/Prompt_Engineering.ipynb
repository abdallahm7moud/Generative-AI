{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ae5rpZDyscx"
      },
      "source": [
        "## Accessing Llama 3 via Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m08554gTqZ7N"
      },
      "source": [
        " Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uffQUNyWi0i0",
        "outputId": "e60a3ef1-55e4-4ac5-dfb6-c36d88993b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Command '['/content/llama-lab/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n",
            "/bin/bash: line 1: llama-lab/bin/activate: No such file or directory\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# Create a virtual environment (optional but recommended)\n",
        "!python -m venv llama-lab\n",
        "!source llama-lab/bin/activate   # On Windows: llama-lab\\Scripts\\activate\n",
        "# Install required packages\n",
        "!pip install transformers torch pandas matplotlib numpy accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUcdm4yuqegI"
      },
      "source": [
        "API Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPr850b_nfiK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Set your Hugging Face token\n",
        "os.environ[\"HUGGINGFACE_TOKEN\"] = \"YOUR_HF_TOKEN\"  # Replace with your actual token\n",
        "\n",
        "# Alternatively, you can login via the CLI with: huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VJwSMg_rQE6"
      },
      "source": [
        "Loading Llama 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "6e6ae9cdbbcd424986c18c02d8ff875e",
            "73bad045d37542d7828dfa95e9268105",
            "dca1a7c18fb3419697c443e45ffce1bd",
            "ab261544262e4ce899a5ef5b51f09590",
            "b650883cf03f402092b8110d6856f9a0",
            "423706f4620c40849aa8fab4c1dc045a",
            "e0163877db2540f5b0564174a3f121d6",
            "16b41f2d71414d26b211d178bc37aabf",
            "9ba2d1c3ba8a487bb17be9714daa693c",
            "82e69219534e45dfb846ba47c4429274",
            "4951bb19b25f456c82e49c07054a3773",
            "0f4a3c9298904434a1ca68943d44502c",
            "5ff044cc4a84432f8d57bd227e5083ec",
            "7ba204cf9f5f4c5e8881bdb1e84a3821",
            "dbbcb2fa585a49aeb00f715df6c18656",
            "523581123fe5476cb2bbb9cfc3bd913e",
            "9d5fd1455b194e7da1d3bc19732d0dc8",
            "14878143963149558febbbe901d6f7ed",
            "26a596debcb54e07993b0f883a1f7176",
            "eb85762a102149369e19cfea1b8c9ce0",
            "da2a9c4b795f4c9a95186e4edc96e4b2",
            "01969153bc1b4018b333997345ca2e77"
          ]
        },
        "id": "uIQdWKk4rQQS",
        "outputId": "bf8be6fb-443b-4161-e059-c12c5209266f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading meta-llama/Llama-3.2-1B-Instruct...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e6ae9cdbbcd424986c18c02d8ff875e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f4a3c9298904434a1ca68943d44502c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "def initialize_llama3(model_id=\"meta-llama/Llama-3.2-1B-Instruct\", use_4bit=True):\n",
        "    \"\"\"\n",
        "    Initialize Llama 3 model from Hugging Face.\n",
        "\n",
        "    Args:\n",
        "        model_id (str): Hugging Face model ID.\n",
        "        use_4bit (bool): Whether to use 4-bit quantization for memory efficiency.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, pipeline)\n",
        "    \"\"\"\n",
        "    print(f\"Loading {model_id}...\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_id,\n",
        "        token=os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
        "    )\n",
        "\n",
        "    if use_4bit:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            token=os.environ.get(\"HUGGINGFACE_TOKEN\"),\n",
        "            # Remove redundant load_in_4bit argument\n",
        "            # load_in_4bit=True,\n",
        "            quantization_config={\n",
        "                \"load_in_4bit\": True,\n",
        "                \"bnb_4bit_compute_dtype\": torch.bfloat16,\n",
        "                \"bnb_4bit_quant_type\": \"nf4\",\n",
        "                \"bnb_4bit_use_double_quant\": True,\n",
        "            }\n",
        "        )\n",
        "    else:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            token=os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
        "        )\n",
        "\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=512,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        return_full_text=False\n",
        "    )\n",
        "\n",
        "    return model, tokenizer, pipe\n",
        "\n",
        "# Initialize the model\n",
        "model, tokenizer, llama3_pipe = initialize_llama3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YcIooBrslnG"
      },
      "source": [
        "Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ln_E_rm2sl0S"
      },
      "outputs": [],
      "source": [
        "def query_llm(prompt, max_new_tokens=500, temperature=0.7):\n",
        "    \"\"\"\n",
        "    Send a prompt to Llama 3 and get a response.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The prompt to send to the model.\n",
        "        max_new_tokens (int): Maximum length of the response.\n",
        "        temperature (float): Controls randomness (0–1).\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Format the prompt according to Llama 3's chat template\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "        formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "\n",
        "        # Generate the response\n",
        "        result = llama3_pipe(\n",
        "            formatted_prompt,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            do_sample=True,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "        return result[0][\"generated_text\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying Llama 3: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def calculate_response_metrics(response):\n",
        "    \"\"\"\n",
        "    Calculate basic metrics about the response.\n",
        "\n",
        "    Args:\n",
        "        response (str): The model's response.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of metrics.\n",
        "    \"\"\"\n",
        "    metrics = {\n",
        "        \"word_count\": len(response.split()),\n",
        "        \"char_count\": len(response),\n",
        "        \"sentence_count\": response.count('. ') + response.count('! ') + response.count('? ')\n",
        "    }\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OI3peRwszUL"
      },
      "source": [
        "Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_waQCNCDszoe",
        "outputId": "70f82555-4331-4a34-89c9-e08ee12968f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant\n",
            "\n",
            "Prompt engineering is the process of designing and crafting effective and coherent prompts that are used to generate human-like responses from AI models, such as language generators, chatbots, and other conversational interfaces. The goal of prompt engineering is to create prompts that are clear, concise, and context-specific, allowing AI models to generate accurate and relevant responses.\n",
            "\n",
            "Effective prompt engineering involves several key considerations:\n",
            "\n",
            "1. **Understanding the context**: The prompt should provide enough context to allow the AI model to understand the topic, intent, or task at hand.\n",
            "2. **Keyword selection**: Choosing the right keywords, phrases, or tokens can significantly impact the quality of the response.\n",
            "3. **Conversational flow**: The prompt should guide the AI model through a natural conversation flow, avoiding awkward or unnatural transitions.\n",
            "4. **Tone and style**: The tone and style of the prompt should match the desired conversational tone and style.\n",
            "5. **Intent detection**: The prompt should indicate the intended intent or goal of the conversation.\n",
            "\n",
            "Prompts can be categorized into different types, such as:\n",
            "\n",
            "1. **Direct prompts**: Providing a direct instruction for the AI model to generate a specific response.\n",
            "2. **Indirect prompts**: Using phrases or sentences that suggest a response but don't specify it directly.\n",
            "3. **Negatives**: Asking the AI model to avoid or counter specific responses.\n",
            "\n",
            "Effective prompt engineering can help:\n",
            "\n",
            "1. **Improve AI model performance**: By providing more accurate and relevant responses.\n",
            "2. **Enhance user experience**: By creating more natural and engaging conversations.\n",
            "3. **Reduce training data**: By reducing the need for large amounts of training data.\n",
            "\n",
            "However, prompt engineering also has limitations and challenges, such as:\n",
            "\n",
            "1. **Overfitting**: Creating prompts that are too specific or detailed, leading to overfitting.\n",
            "2. **Underfitting**: Creating prompts that are too general or vague, leading to underfitting.\n",
            "3. **Adversarial prompts**: Creating prompts that are intentionally misleading or misleading.\n",
            "\n",
            "By mastering the art of prompt engineering, developers can create more effective and efficient AI models, leading to better user experiences and improved AI performance.\n"
          ]
        }
      ],
      "source": [
        "# Test the Llama 3 setup\n",
        "test_prompt = \"What is prompt engineering?\"\n",
        "response = query_llm(test_prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2j2OpH-vLCS"
      },
      "source": [
        "### Zero-shot vs. Few-shot Prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFPdZby8vORL"
      },
      "source": [
        "Setup for Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8Vib-92Cuh16"
      },
      "outputs": [],
      "source": [
        "# Define a set of tasks for comparison\n",
        "tasks = [\n",
        "    \"Classify the following review as positive or negative: 'The service was terrible but the food was amazing.'\",\n",
        "    \"Identify the emotion in this sentence: 'I can't believe I failed the exam after studying so hard.'\",\n",
        "    \"Categorize this news headline as politics, sports, or entertainment: 'New trade agreement signed between countries.'\",\n",
        "    \"Determine if this statement is a fact or opinion: 'Coffee is the best beverage for morning productivity.'\"\n",
        "]\n",
        "\n",
        "# Define few-shot examples for each task\n",
        "few_shot_examples = {\n",
        "    \"sentiment\": [\n",
        "        {\"example\": \"The movie was fantastic and I enjoyed every minute.\", \"label\": \"Positive\"},\n",
        "        {\"example\": \"The hotel room was dirty and the staff was rude.\", \"label\": \"Negative\"},\n",
        "        {\"example\": \"While the price was high, the quality was worth it.\", \"label\": \"Positive\"}\n",
        "    ],\n",
        "    \"emotion\": [\n",
        "        {\"example\": \"I just won the lottery!\", \"label\": \"Joy\"},\n",
        "        {\"example\": \"My dog passed away yesterday.\", \"label\": \"Sadness\"},\n",
        "        {\"example\": \"They didn't invite me to the party.\", \"label\": \"Disappointment\"}\n",
        "    ],\n",
        "    \"categorization\": [\n",
        "        {\"example\": \"Local election results surprise analysts.\", \"label\": \"Politics\"},\n",
        "        {\"example\": \"New movie breaks box office records.\", \"label\": \"Entertainment\"},\n",
        "        {\"example\": \"Team wins championship for the third time.\", \"label\": \"Sports\"}\n",
        "    ],\n",
        "    \"fact_opinion\": [\n",
        "        {\"example\": \"The Earth orbits around the Sun.\", \"label\": \"Fact\"},\n",
        "        {\"example\": \"Summer is the best season of the year.\", \"label\": \"Opinion\"},\n",
        "        {\"example\": \"Chocolate contains caffeine.\", \"label\": \"Fact\"}\n",
        "    ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RJOlaDTvhJr"
      },
      "source": [
        " Implementing Zero-shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5K4YMlLvedy",
        "outputId": "754066d7-86a7-4b01-e62b-3fefa7125f05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task: Classify the following review as positive or negative: 'The service was terrible but the food was amazing.'\n",
            "Response: assistant\n",
            "\n",
            "This review is mixed. It's negative in that the reviewer mentions \"terrible\" service, but positive in that the food was \"amazing.\"\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task: Identify the emotion in this sentence: 'I can't believe I failed the exam after studying so hard.'\n",
            "Response: assistant\n",
            "\n",
            "The emotion expressed in this sentence is disappointment or frustration. The speaker is expressing their disappointment and frustration with not passing the exam despite their hard work and effort.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task: Categorize this news headline as politics, sports, or entertainment: 'New trade agreement signed between countries.'\n",
            "Response: assistant\n",
            "\n",
            "I would categorize this news headline as 'politics'.\n",
            "\n",
            "Task: Determine if this statement is a fact or opinion: 'Coffee is the best beverage for morning productivity.'\n",
            "Response: assistant\n",
            "\n",
            "This statement is an opinion. \n",
            "\n",
            "While coffee can be beneficial for some people's morning routines, it is not universally agreed upon as the best beverage for morning productivity. Different people may have different preferences, and what works for one person may not work for another. Additionally, there may be other factors, such as individual sensitivity to caffeine or certain health conditions, that can affect how coffee affects someone's productivity.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def zero_shot_prompt(task):\n",
        "    \"\"\"\n",
        "    Perform zero-shot prompting for a given task.\n",
        "\n",
        "    Args:\n",
        "        task (str): The task to perform.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response.\n",
        "    \"\"\"\n",
        "    return query_llm(task)\n",
        "\n",
        "# Test zero-shot prompting on our tasks\n",
        "zero_shot_results = []\n",
        "\n",
        "for task in tasks:\n",
        "    response = zero_shot_prompt(task)\n",
        "    result = {\n",
        "        \"task\": task,\n",
        "        \"response\": response,\n",
        "        \"metrics\": calculate_response_metrics(response) if response else None\n",
        "    }\n",
        "    zero_shot_results.append(result)\n",
        "\n",
        "    print(f\"Task: {task}\")\n",
        "    print(f\"Response: {response}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVzrkJZbv9wc"
      },
      "source": [
        "Implementing Few-shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_jOVLBdv-AK",
        "outputId": "55fefbf9-6917-407e-f74d-f42cfd012d9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task: Classify the following review as positive or negative: 'The service was terrible but the food was amazing.'\n",
            "Examples used: sentiment\n",
            "Response: assistant\n",
            "\n",
            "It seems like you're looking for a sentiment analysis tool. Based on the examples you provided, here are some possible outputs for the examples you gave:\n",
            "\n",
            "Input: The movie was fantastic and I enjoyed every minute.\n",
            "Output: Positive\n",
            "\n",
            "Input: The hotel room was dirty and the staff was rude.\n",
            "Output: Negative\n",
            "\n",
            "Input: While the price was high, the quality was worth it.\n",
            "Output: Neutral\n",
            "\n",
            "Input: 'The service was terrible but the food was amazing.'\n",
            "Output: Neutral\n",
            "\n",
            "It appears that your goal is to generate responses that are generally positive, as you mentioned enjoying every minute of a good experience. However, the responses you provided earlier were neutral or negative. To improve, I could suggest some possible improvements:\n",
            "\n",
            "1. Adding a positive phrase to each sentence:\n",
            "Input: The movie was fantastic and I enjoyed every minute.\n",
            "Output: Positive\n",
            "Input: The hotel room was dirty and the staff was rude.\n",
            "Output: Negative\n",
            "Input: While the price was high, the quality was worth it.\n",
            "Output: Neutral\n",
            "Input: 'The service was terrible but the food was amazing.'\n",
            "Output: Neutral\n",
            "\n",
            "2. Using more descriptive language:\n",
            "Input: The movie was fantastic and I enjoyed every minute of it.\n",
            "Output: Positive\n",
            "Input: The hotel room was dirty and the staff was rude.\n",
            "Output: Negative\n",
            "Input: While the price was high, the quality was worth it.\n",
            "Output: Neutral\n",
            "Input: 'The service was terrible but the food was amazing.'\n",
            "Output: Neutral\n",
            "\n",
            "3. Using a more nuanced approach:\n",
            "Input: The movie was fantastic and I thoroughly enjoyed every minute.\n",
            "Output: Positive\n",
            "Input: The hotel room was dirty and the staff was rude.\n",
            "Output: Negative\n",
            "Input: While the price was high, the quality was worth it.\n",
            "Output: Neutral\n",
            "Input: 'The service was terrible but the food was amazing.'\n",
            "Output: Neutral\n",
            "\n",
            "These are just suggestions. Do you have any specific requirements or preferences for the responses?\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task: Identify the emotion in this sentence: 'I can't believe I failed the exam after studying so hard.'\n",
            "Examples used: emotion\n",
            "Response: assistant\n",
            "\n",
            "Based on the patterns observed from the examples, I'll try to infer the correct output.\n",
            "\n",
            "From the examples:\n",
            "\n",
            "1. \"I just won the lottery!\" - Joy\n",
            "2. \"My dog passed away yesterday.\" - Sadness\n",
            "3. \"They didn't invite me to the party.\" - Disappointment\n",
            "\n",
            "It seems that the sentiment is the opposite of what the word or phrase typically means. Here's a possible pattern:\n",
            "\n",
            "- Joy (excitement or happiness) is not always associated with winning a lottery.\n",
            "- Sadness is often associated with the loss of something, not the gain.\n",
            "- Disappointment is usually associated with a missed opportunity, not an actual event that occurred.\n",
            "\n",
            "If I apply this pattern to the given examples, here's what I would expect the output to be for the new input:\n",
            "\n",
            "Input: I had a meeting with a potential investor.\n",
            "Output:\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task: Categorize this news headline as politics, sports, or entertainment: 'New trade agreement signed between countries.'\n",
            "Examples used: categorization\n",
            "Response: assistant\n",
            "\n",
            "It seems like you're trying to predict the output based on the input. \n",
            "\n",
            "The pattern appears to be that the input is related to a specific topic, and the output is the opposite topic. \n",
            "\n",
            "Let's break it down:\n",
            "\n",
            "- Local election results surprise analysts: \n",
            "  - Local = Local (Geographic location)\n",
            "  - Election results = Politics\n",
            "  - Surprise analysts = Analysis (Concerns or insights about the outcome)\n",
            "\n",
            "- New movie breaks box office records:\n",
            "  - New = New (Something new)\n",
            "  - Movie = Entertainment\n",
            "  - Box office records = Box office (A measure of a movie's success)\n",
            "\n",
            "- Team wins championship for the third time:\n",
            "  - Team = Team (A group of people)\n",
            "  - Championship = Sports\n",
            "  - Wins championship = Wins (Success in a competitive event)\n",
            "\n",
            "- 'New trade agreement signed between countries.'\n",
            "  - New = New (Something new)\n",
            "  - Trade agreement = Trade (An agreement between countries)\n",
            "  - Signed = Signed (Something that has been done)\n",
            "  - Between countries = Countries (Two or more countries involved in the agreement)\n",
            "\n",
            "Applying this pattern, the output for the new trade agreement between countries would be: Trade agreement.\n",
            "\n",
            "Task: Determine if this statement is a fact or opinion: 'Coffee is the best beverage for morning productivity.'\n",
            "Examples used: fact_opinion\n",
            "Response: assistant\n",
            "\n",
            "It seems like you're trying to test the categorization of the input examples.\n",
            "\n",
            "Input: 'Coffee is the best beverage for morning productivity.'\n",
            "Output: Opinion\n",
            "\n",
            "The reason is that the statement \"Coffee is the best beverage for morning productivity\" is subjective and based on personal preference, making it an opinion rather than a fact.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def few_shot_prompt(task, examples):\n",
        "    \"\"\"\n",
        "    Perform few-shot prompting for a given task.\n",
        "\n",
        "    Args:\n",
        "        task (str): The task to perform.\n",
        "        examples (list): List of example dictionaries with 'example' and 'label' keys.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response.\n",
        "    \"\"\"\n",
        "    # Construct the prompt with examples\n",
        "    prompt = \"Here are some examples:\\n\\n\"\n",
        "\n",
        "    for example in examples:\n",
        "        prompt += f\"Input: {example['example']}\\nOutput: {example['label']}\\n\\n\"\n",
        "\n",
        "    input_text = task.split(': ', 1)[1] if ': ' in task else task\n",
        "    prompt += f\"Input: {input_text}\\nOutput:\"\n",
        "\n",
        "    return query_llm(prompt)\n",
        "\n",
        "# Determine which examples to use for each task\n",
        "task_to_examples = {\n",
        "    0: \"sentiment\",\n",
        "    1: \"emotion\",\n",
        "    2: \"categorization\",\n",
        "    3: \"fact_opinion\"\n",
        "}\n",
        "\n",
        "# Test few-shot prompting on our tasks\n",
        "few_shot_results = []\n",
        "\n",
        "for i, task in enumerate(tasks):\n",
        "    example_type = task_to_examples[i]\n",
        "    examples = few_shot_examples[example_type]\n",
        "\n",
        "    response = few_shot_prompt(task, examples)\n",
        "\n",
        "    few_shot_results.append({\n",
        "        \"task\": task,\n",
        "        \"response\": response,\n",
        "        \"metrics\": calculate_response_metrics(response) if response else None,\n",
        "        \"example_type\": example_type\n",
        "    })\n",
        "\n",
        "    print(f\"Task: {task}\")\n",
        "    print(f\"Examples used: {example_type}\")\n",
        "    print(f\"Response: {response}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0FM74GvwFsi"
      },
      "source": [
        "Comparing Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrFACN0pwGb7",
        "outputId": "e640fb59-47f4-4d85-b4d0-d0a87f34a362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                Task  \\\n",
            "0  Classify the following review as positive or n...   \n",
            "1  Identify the emotion in this sentence: 'I can'...   \n",
            "2  Categorize this news headline as politics, spo...   \n",
            "3  Determine if this statement is a fact or opini...   \n",
            "\n",
            "                                  Zero-shot Response  \\\n",
            "0  assistant\\n\\nThis review is mixed. It's negati...   \n",
            "1  assistant\\n\\nThe emotion expressed in this sen...   \n",
            "2  assistant\\n\\nI would categorize this news head...   \n",
            "3  assistant\\n\\nThis statement is an opinion. \\n\\...   \n",
            "\n",
            "                                   Few-shot Response  \n",
            "0  assistant\\n\\nIt seems like you're looking for ...  \n",
            "1  assistant\\n\\nBased on the patterns observed fr...  \n",
            "2  assistant\\n\\nIt seems like you're trying to pr...  \n",
            "3  assistant\\n\\nIt seems like you're trying to te...  \n"
          ]
        }
      ],
      "source": [
        "# Create a comparison dataframe\n",
        "comparison_data = []\n",
        "\n",
        "for i in range(len(tasks)):\n",
        "    comparison_data.append({\n",
        "        \"Task\": tasks[i],\n",
        "        \"Zero-shot Response\": zero_shot_results[i][\"response\"],\n",
        "        \"Few-shot Response\": few_shot_results[i][\"response\"]\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df)\n",
        "\n",
        "# You can also save this to a CSV for further analysis\n",
        "comparison_df.to_csv(\"zero_shot_vs_few_shot_comparison.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "h8WNxj_PwxEH",
        "outputId": "29230d9c-22c0-4aec-9caf-7f17e41f4c63"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Task\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Identify the emotion in this sentence: 'I can't believe I failed the exam after studying so hard.'\",\n          \"Determine if this statement is a fact or opinion: 'Coffee is the best beverage for morning productivity.'\",\n          \"Classify the following review as positive or negative: 'The service was terrible but the food was amazing.'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Zero-shot Response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"assistant\\n\\nThe emotion expressed in this sentence is disappointment or frustration. The speaker is expressing their disappointment and frustration with not passing the exam despite their hard work and effort.\",\n          \"assistant\\n\\nThis statement is an opinion. \\n\\nWhile coffee can be beneficial for some people's morning routines, it is not universally agreed upon as the best beverage for morning productivity. Different people may have different preferences, and what works for one person may not work for another. Additionally, there may be other factors, such as individual sensitivity to caffeine or certain health conditions, that can affect how coffee affects someone's productivity.\",\n          \"assistant\\n\\nThis review is mixed. It's negative in that the reviewer mentions \\\"terrible\\\" service, but positive in that the food was \\\"amazing.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Few-shot Response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"assistant\\n\\nBased on the patterns observed from the examples, I'll try to infer the correct output.\\n\\nFrom the examples:\\n\\n1. \\\"I just won the lottery!\\\" - Joy\\n2. \\\"My dog passed away yesterday.\\\" - Sadness\\n3. \\\"They didn't invite me to the party.\\\" - Disappointment\\n\\nIt seems that the sentiment is the opposite of what the word or phrase typically means. Here's a possible pattern:\\n\\n- Joy (excitement or happiness) is not always associated with winning a lottery.\\n- Sadness is often associated with the loss of something, not the gain.\\n- Disappointment is usually associated with a missed opportunity, not an actual event that occurred.\\n\\nIf I apply this pattern to the given examples, here's what I would expect the output to be for the new input:\\n\\nInput: I had a meeting with a potential investor.\\nOutput:\",\n          \"assistant\\n\\nIt seems like you're trying to test the categorization of the input examples.\\n\\nInput: 'Coffee is the best beverage for morning productivity.'\\nOutput: Opinion\\n\\nThe reason is that the statement \\\"Coffee is the best beverage for morning productivity\\\" is subjective and based on personal preference, making it an opinion rather than a fact.\",\n          \"assistant\\n\\nIt seems like you're looking for a sentiment analysis tool. Based on the examples you provided, here are some possible outputs for the examples you gave:\\n\\nInput: The movie was fantastic and I enjoyed every minute.\\nOutput: Positive\\n\\nInput: The hotel room was dirty and the staff was rude.\\nOutput: Negative\\n\\nInput: While the price was high, the quality was worth it.\\nOutput: Neutral\\n\\nInput: 'The service was terrible but the food was amazing.'\\nOutput: Neutral\\n\\nIt appears that your goal is to generate responses that are generally positive, as you mentioned enjoying every minute of a good experience. However, the responses you provided earlier were neutral or negative. To improve, I could suggest some possible improvements:\\n\\n1. Adding a positive phrase to each sentence:\\nInput: The movie was fantastic and I enjoyed every minute.\\nOutput: Positive\\nInput: The hotel room was dirty and the staff was rude.\\nOutput: Negative\\nInput: While the price was high, the quality was worth it.\\nOutput: Neutral\\nInput: 'The service was terrible but the food was amazing.'\\nOutput: Neutral\\n\\n2. Using more descriptive language:\\nInput: The movie was fantastic and I enjoyed every minute of it.\\nOutput: Positive\\nInput: The hotel room was dirty and the staff was rude.\\nOutput: Negative\\nInput: While the price was high, the quality was worth it.\\nOutput: Neutral\\nInput: 'The service was terrible but the food was amazing.'\\nOutput: Neutral\\n\\n3. Using a more nuanced approach:\\nInput: The movie was fantastic and I thoroughly enjoyed every minute.\\nOutput: Positive\\nInput: The hotel room was dirty and the staff was rude.\\nOutput: Negative\\nInput: While the price was high, the quality was worth it.\\nOutput: Neutral\\nInput: 'The service was terrible but the food was amazing.'\\nOutput: Neutral\\n\\nThese are just suggestions. Do you have any specific requirements or preferences for the responses?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "comparison_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bcc57df7-18fd-479d-a68f-5d2bbd7105f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Task</th>\n",
              "      <th>Zero-shot Response</th>\n",
              "      <th>Few-shot Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Classify the following review as positive or n...</td>\n",
              "      <td>assistant\\n\\nThis review is mixed. It's negati...</td>\n",
              "      <td>assistant\\n\\nIt seems like you're looking for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Identify the emotion in this sentence: 'I can'...</td>\n",
              "      <td>assistant\\n\\nThe emotion expressed in this sen...</td>\n",
              "      <td>assistant\\n\\nBased on the patterns observed fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Categorize this news headline as politics, spo...</td>\n",
              "      <td>assistant\\n\\nI would categorize this news head...</td>\n",
              "      <td>assistant\\n\\nIt seems like you're trying to pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Determine if this statement is a fact or opini...</td>\n",
              "      <td>assistant\\n\\nThis statement is an opinion. \\n\\...</td>\n",
              "      <td>assistant\\n\\nIt seems like you're trying to te...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcc57df7-18fd-479d-a68f-5d2bbd7105f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcc57df7-18fd-479d-a68f-5d2bbd7105f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcc57df7-18fd-479d-a68f-5d2bbd7105f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-814bd968-16fd-4ada-b0c1-195182b81a36\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-814bd968-16fd-4ada-b0c1-195182b81a36')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-814bd968-16fd-4ada-b0c1-195182b81a36 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_2f3311bf-9b67-4c70-aaf8-cb2369e28a20\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2f3311bf-9b67-4c70-aaf8-cb2369e28a20 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                Task  \\\n",
              "0  Classify the following review as positive or n...   \n",
              "1  Identify the emotion in this sentence: 'I can'...   \n",
              "2  Categorize this news headline as politics, spo...   \n",
              "3  Determine if this statement is a fact or opini...   \n",
              "\n",
              "                                  Zero-shot Response  \\\n",
              "0  assistant\\n\\nThis review is mixed. It's negati...   \n",
              "1  assistant\\n\\nThe emotion expressed in this sen...   \n",
              "2  assistant\\n\\nI would categorize this news head...   \n",
              "3  assistant\\n\\nThis statement is an opinion. \\n\\...   \n",
              "\n",
              "                                   Few-shot Response  \n",
              "0  assistant\\n\\nIt seems like you're looking for ...  \n",
              "1  assistant\\n\\nBased on the patterns observed fr...  \n",
              "2  assistant\\n\\nIt seems like you're trying to pr...  \n",
              "3  assistant\\n\\nIt seems like you're trying to te...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezn4fsynywpM"
      },
      "source": [
        "## Chain-of-Thought (CoT) Prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVcuHoBsy6MD"
      },
      "source": [
        "Problem Set for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZHAAIR61yKcV"
      },
      "outputs": [],
      "source": [
        "# Define a set of reasoning problems\n",
        "reasoning_problems = [\n",
        "    \"If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price?\",\n",
        "    \"A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\",\n",
        "    \"If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?\",\n",
        "    \"A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFPpE7TmzZOY"
      },
      "source": [
        "Standard Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ArErjJVzWdI",
        "outputId": "3a95baab-3573-4228-b2eb-1d84111dd870"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price?\n",
            "Response: assistant\n",
            "\n",
            "To find the final price, we need to calculate the discount amount first.\n",
            "\n",
            "The original price is $100. \n",
            "25% off: $100 x 0.25 = $25\n",
            "Discounted price: $100 - $25 = $75\n",
            "\n",
            "Now, we add the additional 10% discount to the discounted price:\n",
            "$75 + 10% of $75\n",
            "$75 + ($75 x 0.10)\n",
            "$75 + $7.50\n",
            "$82.50\n",
            "\n",
            "The final price is $82.50.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\n",
            "Response: assistant\n",
            "\n",
            "To find the distance traveled by the train, you need to multiply the speed (60 miles per hour) by the time (2.5 hours).\n",
            "\n",
            "Distance = Speed x Time\n",
            "= 60 miles/hour x 2.5 hours\n",
            "= 150 miles\n",
            "\n",
            "The train will travel 150 miles in 2.5 hours.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?\n",
            "Response: assistant\n",
            "\n",
            "If it takes 5 machines 5 minutes to make 5 widgets, we can start by determining the rate at which one machine makes widgets. \n",
            "\n",
            "5 widgets / 5 minutes = 1 widget per minute per machine\n",
            "\n",
            "Now, we can multiply this rate by the number of machines to get the total rate:\n",
            "\n",
            "1 widget per minute per machine * 100 machines = 100 widgets per minute\n",
            "\n",
            "Since it takes 5 minutes to make 100 widgets, we can divide 100 by 100 to get the time it takes for 100 machines:\n",
            "\n",
            "100 widgets / 100 machines = 1 minute\n",
            "\n",
            "Therefore, it would take 100 machines 1 minute to make 100 widgets.\n",
            "\n",
            "Problem: A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\n",
            "Response: assistant\n",
            "\n",
            "Let's use algebra to solve this problem.\n",
            "\n",
            "Let the cost of the ball be x. Since the bat costs $1.00 more than the ball, the cost of the bat is x + $1.00.\n",
            "\n",
            "We know that the total cost of both the bat and the ball is $1.10. We can set up the equation:\n",
            "\n",
            "x + (x + $1.00) = $1.10\n",
            "\n",
            "Combine like terms:\n",
            "\n",
            "2x + $1.00 = $1.10\n",
            "\n",
            "Subtract $1.00 from both sides:\n",
            "\n",
            "2x = $0.10\n",
            "\n",
            "Divide both sides by 2:\n",
            "\n",
            "x = $0.05\n",
            "\n",
            "So, the ball costs $0.05.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def standard_prompt(problem):\n",
        "    \"\"\"\n",
        "    Perform standard prompting for a reasoning problem.\n",
        "\n",
        "    Args:\n",
        "        problem (str): The reasoning problem\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response\n",
        "    \"\"\"\n",
        "    prompt = f\"Answer the following question: {problem}\"\n",
        "    return query_llm(prompt)\n",
        "\n",
        "# Test standard prompting on our reasoning problems\n",
        "standard_results = []\n",
        "for problem in reasoning_problems:\n",
        "    response = standard_prompt(problem)\n",
        "    standard_results.append({\n",
        "        \"problem\": problem,\n",
        "        \"response\": response\n",
        "    })\n",
        "    print(f\"Problem: {problem}\")\n",
        "    print(f\"Response: {response}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAIYVY9Zz4Sr"
      },
      "source": [
        "Chain-of-Thought Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "684rVaFwziYN",
        "outputId": "62a4065f-4237-4766-afa7-fb5f3c02e87b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price?\n",
            "CoT Response: assistant\n",
            "\n",
            "To find the final price, let's break it down step by step:\n",
            "\n",
            "1. The original price of the shirt is $100.\n",
            "2. The first discount is 25%. To find the amount of the discount, multiply the original price by the discount percentage:\n",
            "   25% of $100 = 0.25 x $100 = $25\n",
            "   The discount is $25.\n",
            "3. Subtract the discount from the original price to find the price after the first discount:\n",
            "   $100 - $25 = $75\n",
            "4. The second discount is 10%. To find the amount of the second discount, multiply the price after the first discount by the second discount percentage:\n",
            "   10% of $75 = 0.10 x $75 = $7.50\n",
            "   The second discount is $7.50.\n",
            "5. Subtract the second discount from the price after the first discount:\n",
            "   $75 - $7.50 = $67.50\n",
            "\n",
            "So, the final price of the shirt is $67.50.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\n",
            "CoT Response: assistant\n",
            "\n",
            "To find the distance traveled by the train, we need to multiply the speed of the train by the time it travels.\n",
            "\n",
            "Speed = 60 miles per hour\n",
            "Time = 2.5 hours\n",
            "\n",
            "Distance = Speed x Time\n",
            "= 60 miles/hour x 2.5 hours\n",
            "= 150 miles\n",
            "\n",
            "So, the train will travel 150 miles in 2.5 hours.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?\n",
            "CoT Response: assistant\n",
            "\n",
            "Let's break down the problem step by step:\n",
            "\n",
            "1. If it takes 5 machines 5 minutes to make 5 widgets, we need to find the rate of production per machine.\n",
            "2. Since the total output is 5 widgets and it takes 5 machines 5 minutes, the total time to produce 1 widget is 5 minutes per machine.\n",
            "3. Now, we need to calculate the total time to produce 100 widgets with 100 machines.\n",
            "4. We know that the rate of production per machine is 1 widget per 5 minutes, so the rate per machine is 1/5 widgets per minute.\n",
            "5. Now, we need to find the total time to produce 100 widgets with 100 machines.\n",
            "6. Since the rate per machine is 1/5 widgets per minute, the total time to produce 100 widgets with 100 machines is 100 / (1/5) = 100 * 5 = 500 minutes.\n",
            "\n",
            "Therefore, it would take 100 machines 500 minutes to make 100 widgets.\n",
            "\n",
            "Problem: A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\n",
            "CoT Response: assistant\n",
            "\n",
            "Let's break it down step by step:\n",
            "\n",
            "1. We know that the bat and the ball together cost $1.10.\n",
            "2. The bat costs $1.00 more than the ball, so let's call the cost of the ball \"x\". Then, the cost of the bat would be x + $1.00.\n",
            "3. Since the total cost is $1.10, we can set up the equation: x + (x + $1.00) = $1.10.\n",
            "4. Simplify the equation: 2x + $1.00 = $1.10.\n",
            "5. Subtract $1.00 from both sides: 2x = $0.10.\n",
            "6. Divide both sides by 2: x = $0.05.\n",
            "\n",
            "The ball costs $0.05.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def cot_prompt(problem):\n",
        "    \"\"\"\n",
        "    Perform Chain-of-Thought prompting for a reasoning problem.\n",
        "\n",
        "    Args:\n",
        "        problem (str): The reasoning problem\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response\n",
        "    \"\"\"\n",
        "    prompt = f\"Answer the following question by thinking step by step: {problem}\"\n",
        "    return query_llm(prompt)\n",
        "\n",
        "# Test CoT prompting on our reasoning problems\n",
        "cot_results = []\n",
        "for problem in reasoning_problems:\n",
        "    response = cot_prompt(problem)\n",
        "    cot_results.append({\n",
        "        \"problem\": problem,\n",
        "        \"response\": response\n",
        "    })\n",
        "    print(f\"Problem: {problem}\")\n",
        "    print(f\"CoT Response: {response}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfggllb70Pu8"
      },
      "source": [
        "Few-shot Chain-of-Thought"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRlf0jkl0ITo",
        "outputId": "1c7a1d78-0030-4f30-9cea-07968e29d8fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price?\n",
            "Few-shot CoT Response: assistant\n",
            "\n",
            "To find the final price, we need to first calculate the discount from the original price.\n",
            "\n",
            "Original price = $100\n",
            "Discount = 25% of $100 = 0.25 × $100 = $25\n",
            "Discounted price = Original price - Discount = $100 - $25 = $75\n",
            "\n",
            "Next, we apply the additional 10% discount:\n",
            "Additional discount = 10% of $75 = 0.10 × $75 = $7.50\n",
            "Final price = Discounted price - Additional discount = $75 - $7.50 = $67.50\n",
            "\n",
            "So, the final price of the shirt is $67.50.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\n",
            "Few-shot CoT Response: assistant\n",
            "\n",
            "I can help you solve the next problem. Here's the step-by-step solution:\n",
            "\n",
            "Problem: A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\n",
            "\n",
            "Solution: To find the distance traveled, we multiply the speed by the time.\n",
            "\n",
            "Distance = Speed × Time\n",
            "= 60 miles/hour × 2.5 hours\n",
            "= 60 × 2.5\n",
            "= 150 miles\n",
            "\n",
            "So, the train will travel 150 miles in 2.5 hours.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?\n",
            "Few-shot CoT Response: assistant\n",
            "\n",
            "To solve this problem, we need to determine the rate at which the machines work and then apply it to the larger quantity.\n",
            "\n",
            "First, let's analyze the given information:\n",
            "- 5 machines take 5 minutes to make 5 widgets.\n",
            "- We need to find the time it takes for 100 machines to make 100 widgets.\n",
            "\n",
            "Since the machines work at the same rate, we can determine the rate at which one machine works:\n",
            "- 5 machines make 5 widgets in 5 minutes. To find the rate per minute, we can divide the number of widgets by the number of minutes:\n",
            "  Rate per minute = 5 widgets / 5 minutes = 1 widget/minute\n",
            "- Now, to find the rate for 100 machines, we can multiply the rate per minute by 100:\n",
            "  Rate for 100 machines = 1 widget/minute × 100 machines = 100 widgets/minute\n",
            "\n",
            "Since 1 widget is equal to 1 unit, we can find the time it takes for 100 machines to make 100 widgets:\n",
            "- Time = Total widgets / Rate for 100 machines\n",
            "- Time = 100 widgets / 100 widgets/minute = 1 minute\n",
            "\n",
            "Therefore, it will take 100 machines 1 minute to make 100 widgets.\n",
            "\n",
            "Problem: A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\n",
            "Few-shot CoT Response: assistant\n",
            "\n",
            "I can help you solve the second problem.\n",
            "\n",
            "Problem: A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\n",
            "\n",
            "Solution: Let's say the ball costs x dollars. Then, the bat costs x + $1 dollars. The total cost is $1.10, so we can set up the equation:\n",
            "\n",
            "x + (x + $1) = $1.10\n",
            "\n",
            "Combine like terms:\n",
            "\n",
            "2x + $1 = $1.10\n",
            "\n",
            "Subtract $1 from both sides:\n",
            "\n",
            "2x = $0.10\n",
            "\n",
            "Divide both sides by 2:\n",
            "\n",
            "x = $0.05\n",
            "\n",
            "So, the ball costs $0.05.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def few_shot_cot_prompt(problem):\n",
        "    \"\"\"\n",
        "    Perform few-shot Chain-of-Thought prompting.\n",
        "\n",
        "    Args:\n",
        "        problem (str): The reasoning problem\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response\n",
        "    \"\"\"\n",
        "    prompt = \"\"\"I'll solve some math problems step by step.\n",
        "Problem: If John has 5 apples and gives 2 to Mary, how many apples does John have left?\n",
        "Solution: John starts with 5 apples. He gives 2 apples to Mary. So, John has 5 - 2 = 3 apples left.\n",
        "\n",
        "Problem: A rectangle has a length of 10 cm and a width of 5 cm. What is its area?\n",
        "Solution: The area of a rectangle is calculated by multiplying length × width. So, the area is 10 cm × 5 cm = 50 square cm.\n",
        "\n",
        "Problem: If a car travels at 60 miles per hour, how far will it travel in 2 hours?\n",
        "Solution: Distance = Speed × Time. So, the car will travel 60 miles/hour × 2 hours = 120 miles.\n",
        "\n",
        "Problem: {}\n",
        "Solution:\"\"\".format(problem)\n",
        "\n",
        "    return query_llm(prompt)\n",
        "\n",
        "# Test few-shot CoT prompting on our reasoning problems\n",
        "few_shot_cot_results = []\n",
        "for problem in reasoning_problems:\n",
        "    response = few_shot_cot_prompt(problem)\n",
        "    few_shot_cot_results.append({\n",
        "        \"problem\": problem,\n",
        "        \"response\": response\n",
        "    })\n",
        "    print(f\"Problem: {problem}\")\n",
        "    print(f\"Few-shot CoT Response: {response}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4tnHfok0nYY"
      },
      "source": [
        "Comparing Approaches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51x6y8bg0j56",
        "outputId": "1e5bb4a8-0c2e-4c39-ed74-2662ba55993b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             Problem  \\\n",
            "0  If a shirt originally costs $100 and is on sal...   \n",
            "1  A train travels at a speed of 60 miles per hou...   \n",
            "2  If it takes 5 machines 5 minutes to make 5 wid...   \n",
            "3  A bat and a ball cost $1.10 in total. The bat ...   \n",
            "\n",
            "                                     Standard Answer  \\\n",
            "0                                             $82.50   \n",
            "1                                                      \n",
            "2  5 widgets / 5 minutes = 1 widget per minute pe...   \n",
            "3                                              $0.05   \n",
            "\n",
            "                                          CoT Answer  \\\n",
            "0                                             $67.50   \n",
            "1  5 hours\\n= 150 miles\\n\\nSo, the train will tra...   \n",
            "2  Therefore, it would take 100 machines 500 minu...   \n",
            "3                                              $0.05   \n",
            "\n",
            "                                 Few-shot CoT Answer  \n",
            "0                                             $67.50  \n",
            "1  5\\n= 150 miles\\n\\nSo, the train will travel 15...  \n",
            "2  To find the rate per minute, we can divide the...  \n",
            "3                                              $0.05  \n"
          ]
        }
      ],
      "source": [
        "def extract_final_answer(response):\n",
        "    \"\"\"\n",
        "    Attempt to extract just the final numerical answer from a response.\n",
        "    This is a simple implementation and may need refinement for complex responses.\n",
        "\n",
        "    Args:\n",
        "        response (str): The model's full response\n",
        "\n",
        "    Returns:\n",
        "        str: The extracted final answer, or the original response if extraction fails\n",
        "    \"\"\"\n",
        "    # Look for common patterns in answers\n",
        "    if \"$\" in response:\n",
        "        # Try to find monetary amounts\n",
        "        import re\n",
        "        matches = re.findall(r'\\$\\d+\\.?\\d*', response)\n",
        "        if matches:\n",
        "            return matches[-1]  # Return the last monetary amount found\n",
        "\n",
        "    # Look for the last sentence that might contain the answer\n",
        "    sentences = response.split('.')\n",
        "    for sentence in reversed(sentences):\n",
        "        if any(word in sentence.lower() for word in ['answer', 'result', 'therefore', 'so', 'thus', 'final']):\n",
        "            return sentence.strip()\n",
        "\n",
        "    # If we can't extract a specific answer, return the last sentence\n",
        "    if sentences:\n",
        "        return sentences[-1].strip()\n",
        "\n",
        "    return response\n",
        "\n",
        "# Compare the approaches\n",
        "comparison_data = []\n",
        "for i in range(len(reasoning_problems)):\n",
        "    standard_answer = extract_final_answer(standard_results[i][\"response\"])\n",
        "    cot_answer = extract_final_answer(cot_results[i][\"response\"])\n",
        "    few_shot_cot_answer = extract_final_answer(few_shot_cot_results[i][\"response\"])\n",
        "\n",
        "    comparison_data.append({\n",
        "        \"Problem\": reasoning_problems[i],\n",
        "        \"Standard Answer\": standard_answer,\n",
        "        \"CoT Answer\": cot_answer,\n",
        "        \"Few-shot CoT Answer\": few_shot_cot_answer\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df)\n",
        "\n",
        "# Save the comparison to a CSV for further analysis\n",
        "comparison_df.to_csv(\"cot_comparison.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "TMdgddnt1Gi6",
        "outputId": "346fddf6-4213-490c-db3c-0d62bca792c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Problem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\",\n          \"A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\",\n          \"If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Standard Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\",\n          \"$0.05\",\n          \"$82.50\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CoT Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"5 hours\\n= 150 miles\\n\\nSo, the train will travel 150 miles in 2\",\n          \"$0.05\",\n          \"$67.50\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Few-shot CoT Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"5\\n= 150 miles\\n\\nSo, the train will travel 150 miles in 2\",\n          \"$0.05\",\n          \"$67.50\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "comparison_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f82f1893-b0a4-451a-9b9c-01e248ab7178\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Problem</th>\n",
              "      <th>Standard Answer</th>\n",
              "      <th>CoT Answer</th>\n",
              "      <th>Few-shot CoT Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>If a shirt originally costs $100 and is on sal...</td>\n",
              "      <td>$82.50</td>\n",
              "      <td>$67.50</td>\n",
              "      <td>$67.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A train travels at a speed of 60 miles per hou...</td>\n",
              "      <td></td>\n",
              "      <td>5 hours\\n= 150 miles\\n\\nSo, the train will tra...</td>\n",
              "      <td>5\\n= 150 miles\\n\\nSo, the train will travel 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If it takes 5 machines 5 minutes to make 5 wid...</td>\n",
              "      <td>5 widgets / 5 minutes = 1 widget per minute pe...</td>\n",
              "      <td>Therefore, it would take 100 machines 500 minu...</td>\n",
              "      <td>To find the rate per minute, we can divide the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A bat and a ball cost $1.10 in total. The bat ...</td>\n",
              "      <td>$0.05</td>\n",
              "      <td>$0.05</td>\n",
              "      <td>$0.05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f82f1893-b0a4-451a-9b9c-01e248ab7178')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f82f1893-b0a4-451a-9b9c-01e248ab7178 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f82f1893-b0a4-451a-9b9c-01e248ab7178');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-20dee5c3-87eb-4cd7-993e-209d57fb2319\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20dee5c3-87eb-4cd7-993e-209d57fb2319')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-20dee5c3-87eb-4cd7-993e-209d57fb2319 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_797d3d3d-7eff-43ce-9e46-1d7f2d30ee3a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_797d3d3d-7eff-43ce-9e46-1d7f2d30ee3a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             Problem  \\\n",
              "0  If a shirt originally costs $100 and is on sal...   \n",
              "1  A train travels at a speed of 60 miles per hou...   \n",
              "2  If it takes 5 machines 5 minutes to make 5 wid...   \n",
              "3  A bat and a ball cost $1.10 in total. The bat ...   \n",
              "\n",
              "                                     Standard Answer  \\\n",
              "0                                             $82.50   \n",
              "1                                                      \n",
              "2  5 widgets / 5 minutes = 1 widget per minute pe...   \n",
              "3                                              $0.05   \n",
              "\n",
              "                                          CoT Answer  \\\n",
              "0                                             $67.50   \n",
              "1  5 hours\\n= 150 miles\\n\\nSo, the train will tra...   \n",
              "2  Therefore, it would take 100 machines 500 minu...   \n",
              "3                                              $0.05   \n",
              "\n",
              "                                 Few-shot CoT Answer  \n",
              "0                                             $67.50  \n",
              "1  5\\n= 150 miles\\n\\nSo, the train will travel 15...  \n",
              "2  To find the rate per minute, we can divide the...  \n",
              "3                                              $0.05  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S30RzmF1icp"
      },
      "source": [
        "## Tree of Thoughts Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scZDXJTo1pUK"
      },
      "source": [
        "Decision Problems for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vaAHBN8K1kp-"
      },
      "outputs": [],
      "source": [
        "decision_problems = [\n",
        "    \"Should a small business invest in expensive automation technology or hire more staff?\",\n",
        "    \"Is it better to pursue higher education immediately after undergraduate studies or gain work experience first?\",\n",
        "    \"For a city with traffic congestion, should they invest in expanding roads or improving public transportation?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QikNgtS_1xux"
      },
      "source": [
        "Implementing Tree of Thoughts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rkFWwI61vNA",
        "outputId": "27c2b4c2-83dd-4ba2-c736-d0c791788be7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating initial thoughts for: Should a small business invest in expensive automation technology or hire more staff?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating thoughts...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thought: assistant Here are 3 different initial thoughts or... Score: 4\n",
            "Selected best thought: assistant Here are 3 different initial thoughts or approaches to solve the problem of whether a smal...\n",
            "Expanding best thought...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Answer:\n",
            "assistant\n",
            "\n",
            "**Final Answer:**\n",
            "\n",
            "Based on the analysis, I recommend that the small business invests in expensive automation technology. The potential benefits of investing in automation technology include significant cost savings and efficiency gains, improved productivity and revenue growth, and enhanced business strategy and innovation.\n",
            "\n",
            "However, I also highlight the potential risks and challenges associated with automation, including technical complexity and integration challenges, training and re-skilling costs for staff, and potential disruptions to business operations.\n",
            "\n",
            "To mitigate these risks, the business should:\n",
            "\n",
            "1. Conduct thorough risk assessments to identify potential challenges and develop contingency plans.\n",
            "2. Invest in employee training and re-skilling to ensure that staff are equipped to work with the new automation technology.\n",
            "3. Implement a comprehensive testing and validation process to ensure the automation system is functioning as expected.\n",
            "4. Develop a clear business strategy and innovation roadmap to align the automation technology with the company's long-term goals and objectives.\n",
            "5. Establish a robust monitoring and maintenance plan to ensure the automation system continues to operate efficiently and effectively.\n",
            "\n",
            "By taking these steps, the business can minimize the risks associated with automation and maximize its potential benefits, ultimately driving growth and success in the market.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Generating initial thoughts for: Is it better to pursue higher education immediately after undergraduate studies or gain work experience first?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating thoughts...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thought: assistant Here are three different initial thought... Score: 28\n",
            "Selected best thought: assistant Here are three different initial thoughts or approaches to solve the problem of whether it...\n",
            "Expanding best thought...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Answer:\n",
            "assistant\n",
            "\n",
            "Based on the analysis, I recommend **attending university** immediately after undergraduate studies.\n",
            "\n",
            "Here's a detailed explanation:\n",
            "\n",
            "**Reasons:**\n",
            "\n",
            "1. **Increased earning potential:** Studies have shown that students who attend university tend to earn higher salaries than those who do not attend university.\n",
            "2. **Networking opportunities:** University provides a great opportunity to network with peers, professors, and alumni, which can lead to job opportunities and career advancement.\n",
            "3. **Skill development and exposure:** University offers a wide range of courses and programs that can help students develop valuable skills, such as critical thinking, problem-solving, and communication.\n",
            "4. **Access to career opportunities:** Universities have a strong industry network, which can provide students with access to job opportunities and career paths.\n",
            "5. **Personal growth and development:** University provides a supportive learning environment that allows students to develop personally and professionally.\n",
            "\n",
            "**Analysis:**\n",
            "\n",
            "* The cost of attending university is higher than gaining work experience first, but the potential benefits of increased earning potential and networking opportunities outweigh the costs.\n",
            "* The ROI of attending university is higher, with potential salary gains of up to 10% per year.\n",
            "\n",
            "**Implementation Plan:**\n",
            "\n",
            "1. Research and gather information on the costs and benefits of attending university versus gaining work experience first.\n",
            "2. Evaluate the ROI of attending university and gaining work experience first.\n",
            "3. Consider the implications of each option and potential challenges.\n",
            "4. Make a decision based on the analysis.\n",
            "5. Implement the chosen option and monitor the outcomes.\n",
            "\n",
            "By attending university immediately after undergraduate studies, individuals can gain valuable skills, increase their earning potential, and access career opportunities. This decision will lead to a successful career and personal growth, making it the recommended outcome.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Generating initial thoughts for: For a city with traffic congestion, should they invest in expanding roads or improving public transportation?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating thoughts...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thought: assistant Here are three different initial thought... Score: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thought: 1. **Economic Perspective:** Investing in expandin... Score: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thought: 2. **Social Perspective:** Improving public transp... Score: 4\n",
            "Selected best thought: assistant Here are three different initial thoughts or approaches to solve the problem of traffic co...\n",
            "Expanding best thought...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating final answer...\n",
            "\n",
            "Final Answer:\n",
            "assistant\n",
            "\n",
            "**Final Answer:**\n",
            "\n",
            "Based on the analysis, I recommend investing in expanding roads to improve traffic infrastructure. While there are high upfront costs and complexities associated with road expansion, the potential benefits of reduced traffic congestion, improved air quality, and increased economic activity outweigh these costs.\n",
            "\n",
            "**Recommendation:**\n",
            "\n",
            "Implement congestion pricing in high-traffic areas, invest in smart traffic management systems, and encourage alternative modes of transportation through incentives and infrastructure investments. Monitor and evaluate the effectiveness of these measures, and adjust the plan as needed to address emerging challenges and opportunities.\n",
            "\n",
            "**Implementation Plan:**\n",
            "\n",
            "1. Conduct a thorough feasibility study to identify high-traffic areas for congestion pricing and smart traffic management.\n",
            "2. Develop a congestion pricing plan, including the implementation schedule, costs, and benefits.\n",
            "3. Invest in smart traffic management systems, including ITS, traffic signal control systems, and real-time traffic data analytics.\n",
            "4. Implement congestion pricing and smart traffic management in high-traffic areas, starting with a small pilot project to test the effectiveness of the plan.\n",
            "5. Monitor traffic flow and congestion levels, and adjust the plan as needed to address emerging challenges and opportunities.\n",
            "6. Encourage alternative modes of transportation through incentives, such as public transportation subsidies, bike-sharing programs, and car-sharing services.\n",
            "7. Continuously evaluate the effectiveness of the plan, and make adjustments to optimize traffic flow and reduce congestion.\n",
            "\n",
            "**Timeline:**\n",
            "\n",
            "* Feasibility study: 6 months\n",
            "* Congestion pricing plan development: 12 months\n",
            "* Implementation: 2 years\n",
            "* Evaluation and adjustments: Ongoing\n",
            "\n",
            "**Budget:**\n",
            "\n",
            "* Initial investment: $500 million - $1 billion\n",
            "* Annual maintenance and operation costs: $200 million - $500 million\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "Expanding roads is a viable and effective solution to reduce traffic congestion, improve air quality, and increase economic activity. While there are challenges associated with the high upfront costs and complexities of road expansion, the potential benefits of a comprehensive plan should outweigh these costs.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_thoughts(problem, n=3):\n",
        "    \"\"\"\n",
        "    Generate multiple initial thoughts/angles for a problem.\n",
        "\n",
        "    Args:\n",
        "        problem (str): The problem to solve\n",
        "        n (int): Number of thoughts to generate\n",
        "\n",
        "    Returns:\n",
        "        list: List of generated thoughts\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    For the following problem, generate {n} different initial thoughts or approaches to solve it.\n",
        "    Each thought should represent a different perspective or starting point.\n",
        "    Problem: {problem}\n",
        "    Generate {n} distinct thoughts numbered 1-{n}:\n",
        "    \"\"\"\n",
        "\n",
        "    response = query_llm(prompt, max_new_tokens=1000)\n",
        "\n",
        "    # Parse the response to extract individual thoughts\n",
        "    thoughts = []\n",
        "    current_thought = \"\"\n",
        "\n",
        "    for line in response.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Check if line starts with a number followed by period or colon\n",
        "        if any(line.startswith(f\"{i}\") for i in range(1, n+1)):\n",
        "            if current_thought:\n",
        "                thoughts.append(current_thought.strip())\n",
        "            current_thought = line\n",
        "        else:\n",
        "            current_thought += \" \" + line\n",
        "\n",
        "    # Add the last thought\n",
        "    if current_thought:\n",
        "        thoughts.append(current_thought.strip())\n",
        "\n",
        "    # Ensure we have exactly n thoughts (or as many as we could parse)\n",
        "    return thoughts[:n]\n",
        "\n",
        "\n",
        "def evaluate_thought(problem, thought):\n",
        "    \"\"\"\n",
        "    Evaluate a single thought for its potential in solving the problem.\n",
        "\n",
        "    Args:\n",
        "        problem (str): The original problem\n",
        "        thought (str): The thought to evaluate\n",
        "\n",
        "    Returns:\n",
        "        dict: Evaluation results including score and reasoning\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Problem: {problem}\n",
        "    Thought: {thought}\n",
        "    Evaluate this thought on a scale of 1-10 based on:\n",
        "    1. Relevance to the problem\n",
        "    2. Creativity and uniqueness\n",
        "    3. Potential to lead to a good solution\n",
        "    4. Practical feasibility\n",
        "    Provide a numerical score for each criterion, an overall score, and brief reasoning for your evaluation.\n",
        "    \"\"\"\n",
        "\n",
        "    response = query_llm(prompt)\n",
        "\n",
        "    # Extract overall score (this is a simple implementation)\n",
        "    import re\n",
        "    score_match = re.search(r'overall score[:\\s]*(\\d+)', response.lower())\n",
        "\n",
        "    overall_score = 5  # Default middle score\n",
        "    if score_match:\n",
        "        try:\n",
        "            overall_score = int(score_match.group(1))\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    return {\n",
        "        \"thought\": thought,\n",
        "        \"evaluation\": response,\n",
        "        \"score\": overall_score\n",
        "    }\n",
        "\n",
        "\n",
        "def expand_thought(problem, thought):\n",
        "    \"\"\"\n",
        "    Expand a thought with a detailed reasoning path.\n",
        "\n",
        "    Args:\n",
        "        problem (str): The original problem\n",
        "        thought (str): The thought to expand\n",
        "\n",
        "    Returns:\n",
        "        str: Expanded reasoning\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Problem: {problem}\n",
        "    Initial thought: {thought}\n",
        "    Expand this thought into a detailed step-by-step reasoning path that addresses the problem.\n",
        "    Consider implications, potential challenges, and possible outcomes.\n",
        "    \"\"\"\n",
        "\n",
        "    return query_llm(prompt, max_new_tokens=1000)\n",
        "\n",
        "\n",
        "def tot_solve(problem):\n",
        "    \"\"\"\n",
        "    Solve a problem using Tree of Thoughts approach.\n",
        "\n",
        "    Args:\n",
        "        problem (str): The problem to solve\n",
        "\n",
        "    Returns:\n",
        "        dict: Solution details including the thought process and final answer\n",
        "    \"\"\"\n",
        "    # Step 1: Generate multiple initial thoughts\n",
        "    print(f\"Generating initial thoughts for: {problem}\")\n",
        "    thoughts = generate_thoughts(problem, n=3)\n",
        "\n",
        "    # Step 2: Evaluate each thought\n",
        "    print(\"Evaluating thoughts...\")\n",
        "    evaluations = []\n",
        "    for thought in thoughts:\n",
        "        eval_result = evaluate_thought(problem, thought)\n",
        "        evaluations.append(eval_result)\n",
        "        print(f\"Thought: {thought[:50]}... Score: {eval_result['score']}\")\n",
        "\n",
        "    # Step 3: Select the most promising thought\n",
        "    evaluations.sort(key=lambda x: x['score'], reverse=True)\n",
        "    best_thought = evaluations[0]['thought']\n",
        "    print(f\"Selected best thought: {best_thought[:100]}...\")\n",
        "\n",
        "    # Step 4: Expand the most promising thought\n",
        "    print(\"Expanding best thought...\")\n",
        "    expanded_reasoning = expand_thought(problem, best_thought)\n",
        "\n",
        "    # Step 5: Generate final answer based on expanded reasoning\n",
        "    print(\"Generating final answer...\")\n",
        "    prompt = f\"\"\"\n",
        "    Problem: {problem}\n",
        "    Reasoning process:\n",
        "    {expanded_reasoning}\n",
        "    Based on this reasoning, what is the final answer or recommendation for this problem?\n",
        "    Provide a concise but comprehensive answer.\n",
        "    \"\"\"\n",
        "\n",
        "    final_answer = query_llm(prompt)\n",
        "\n",
        "    return {\n",
        "        \"problem\": problem,\n",
        "        \"initial_thoughts\": thoughts,\n",
        "        \"evaluations\": evaluations,\n",
        "        \"best_thought\": best_thought,\n",
        "        \"expanded_reasoning\": expanded_reasoning,\n",
        "        \"final_answer\": final_answer\n",
        "    }\n",
        "\n",
        "\n",
        "# Test ToT on our decision problems\n",
        "tot_results = []\n",
        "for problem in decision_problems:\n",
        "    result = tot_solve(problem)\n",
        "    tot_results.append(result)\n",
        "    print(\"\\nFinal Answer:\")\n",
        "    print(result[\"final_answer\"])\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V4WznwT2RYD"
      },
      "source": [
        "Visualizing the Tree of Thoughts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy1-afHm2Rx1",
        "outputId": "a59fa185-2a00-4854-fb0f-71363923f17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem: Should a small business invest in expensive automation technology or hire more staff?\n",
            "\n",
            "Initial Thoughts:\n",
            "1. assistant Here are 3 different initial thoughts or approaches to solve the problem of whether a small business should invest in expensive automation technology or hire more staff: **1. Economic Efficiency and Cost-Benefit Analysis** From an economic perspective, investing in automation technology can bring significant cost savings and efficiency gains to the business. Here's how: - Automate repetitive and mundane tasks, freeing up staff to focus on more strategic and creative work. - Reduce manual data entry, clerical tasks, and other time-consuming activities that can lead to errors and inefficiencies. - Implement automation tools that can handle tasks such as data processing, customer service, and inventory management, reducing labor costs and increasing productivity. However, there may be initial investment costs associated with implementing automation technology, which may be a significant upfront expense. **2. Human Resource and Business Process Improvement** From a human resource perspective, investing in automation technology can also bring benefits such as: - Enhanced employee productivity and morale, as staff can focus on more complex and creative tasks. - Improved work-life balance, as automation can reduce the workload and allow staff to have more time for personal and professional development. - Better alignment of business processes with the company's goals and values. However, automation may also require significant training and re-skilling of staff, which can be a time-consuming and resource-intensive process. **3. Business Strategy and Innovation** From a business strategy perspective, investing in automation technology can be a strategic decision that aligns with the company's long-term goals and objectives. Here's how: - Automate processes that are not core to the business, allowing the company to focus on high-value tasks and initiatives. - Invest in automation technology that aligns with industry trends and innovations, such as AI-powered customer service chatbots or machine learning-based predictive analytics. - Leverage automation to differentiate the business from competitors and stay ahead of the curve in terms of innovation and competitiveness. (Score: 4)\n",
            "\n",
            "Best Thought Selected: assistant Here are 3 different initial thoughts or approaches to solve the problem of whether a small business should invest in expensive automation technology or hire more staff: **1. Economic Efficiency and Cost-Benefit Analysis** From an economic perspective, investing in automation technology can bring significant cost savings and efficiency gains to the business. Here's how: - Automate repetitive and mundane tasks, freeing up staff to focus on more strategic and creative work. - Reduce manual data entry, clerical tasks, and other time-consuming activities that can lead to errors and inefficiencies. - Implement automation tools that can handle tasks such as data processing, customer service, and inventory management, reducing labor costs and increasing productivity. However, there may be initial investment costs associated with implementing automation technology, which may be a significant upfront expense. **2. Human Resource and Business Process Improvement** From a human resource perspective, investing in automation technology can also bring benefits such as: - Enhanced employee productivity and morale, as staff can focus on more complex and creative tasks. - Improved work-life balance, as automation can reduce the workload and allow staff to have more time for personal and professional development. - Better alignment of business processes with the company's goals and values. However, automation may also require significant training and re-skilling of staff, which can be a time-consuming and resource-intensive process. **3. Business Strategy and Innovation** From a business strategy perspective, investing in automation technology can be a strategic decision that aligns with the company's long-term goals and objectives. Here's how: - Automate processes that are not core to the business, allowing the company to focus on high-value tasks and initiatives. - Invest in automation technology that aligns with industry trends and innovations, such as AI-powered customer service chatbots or machine learning-based predictive analytics. - Leverage automation to differentiate the business from competitors and stay ahead of the curve in terms of innovation and competitiveness.\n",
            "\n",
            "Final Answer: assistant\n",
            "\n",
            "**Final Answer:**\n",
            "\n",
            "Based on the analysis, I recommend that the small business invests in expensive automation technology. The potential benefits of investing in automation technology include significant cost savings and efficiency gains, improved productivity and revenue growth, and enhanced business strategy and innovation.\n",
            "\n",
            "However, I also highlight the potential risks and challenges associated with automation, including technical complexity and integration challenges, training and re-skilling costs for staff, and potential disruptions to business operations.\n",
            "\n",
            "To mitigate these risks, the business should:\n",
            "\n",
            "1. Conduct thorough risk assessments to identify potential challenges and develop contingency plans.\n",
            "2. Invest in employee training and re-skilling to ensure that staff are equipped to work with the new automation technology.\n",
            "3. Implement a comprehensive testing and validation process to ensure the automation system is functioning as expected.\n",
            "4. Develop a clear business strategy and innovation roadmap to align the automation technology with the company's long-term goals and objectives.\n",
            "5. Establish a robust monitoring and maintenance plan to ensure the automation system continues to operate efficiently and effectively.\n",
            "\n",
            "By taking these steps, the business can minimize the risks associated with automation and maximize its potential benefits, ultimately driving growth and success in the market.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Problem: Is it better to pursue higher education immediately after undergraduate studies or gain work experience first?\n",
            "\n",
            "Initial Thoughts:\n",
            "1. assistant Here are three different initial thoughts or approaches to solve the problem of whether it's better to pursue higher education immediately after undergraduate studies or gain work experience first: **1. The Traditional Approach** This approach prioritizes the traditional path to success. It suggests that students should prioritize completing their undergraduate degree first and then applying for jobs. This approach assumes that a higher education degree will provide a strong foundation for future career opportunities and higher salaries. The reasoning is based on the idea that a degree will provide a broad-based education that will make students more attractive to employers. **2. The Flexibility Approach** This approach emphasizes the importance of flexibility and adaptability in today's job market. It suggests that students should not be tied to a specific career path or industry, but instead focus on gaining work experience first and then pursuing higher education. This approach recognizes that the job market is constantly evolving, and that students should be prepared to adapt to changing circumstances. **3. The ROI Approach** This approach takes a more pragmatic and financial perspective. It suggests that students should consider the Return on Investment (ROI) of pursuing higher education immediately after undergraduate studies versus gaining work experience first. This approach calculates the potential cost of attending university versus gaining work experience, and then compares it to the potential salary gains. The reasoning is based on the idea that students should weigh the potential financial benefits of attending university against the potential costs, and make a decision based on the most attractive outcome. (Score: 28)\n",
            "\n",
            "Best Thought Selected: assistant Here are three different initial thoughts or approaches to solve the problem of whether it's better to pursue higher education immediately after undergraduate studies or gain work experience first: **1. The Traditional Approach** This approach prioritizes the traditional path to success. It suggests that students should prioritize completing their undergraduate degree first and then applying for jobs. This approach assumes that a higher education degree will provide a strong foundation for future career opportunities and higher salaries. The reasoning is based on the idea that a degree will provide a broad-based education that will make students more attractive to employers. **2. The Flexibility Approach** This approach emphasizes the importance of flexibility and adaptability in today's job market. It suggests that students should not be tied to a specific career path or industry, but instead focus on gaining work experience first and then pursuing higher education. This approach recognizes that the job market is constantly evolving, and that students should be prepared to adapt to changing circumstances. **3. The ROI Approach** This approach takes a more pragmatic and financial perspective. It suggests that students should consider the Return on Investment (ROI) of pursuing higher education immediately after undergraduate studies versus gaining work experience first. This approach calculates the potential cost of attending university versus gaining work experience, and then compares it to the potential salary gains. The reasoning is based on the idea that students should weigh the potential financial benefits of attending university against the potential costs, and make a decision based on the most attractive outcome.\n",
            "\n",
            "Final Answer: assistant\n",
            "\n",
            "Based on the analysis, I recommend **attending university** immediately after undergraduate studies.\n",
            "\n",
            "Here's a detailed explanation:\n",
            "\n",
            "**Reasons:**\n",
            "\n",
            "1. **Increased earning potential:** Studies have shown that students who attend university tend to earn higher salaries than those who do not attend university.\n",
            "2. **Networking opportunities:** University provides a great opportunity to network with peers, professors, and alumni, which can lead to job opportunities and career advancement.\n",
            "3. **Skill development and exposure:** University offers a wide range of courses and programs that can help students develop valuable skills, such as critical thinking, problem-solving, and communication.\n",
            "4. **Access to career opportunities:** Universities have a strong industry network, which can provide students with access to job opportunities and career paths.\n",
            "5. **Personal growth and development:** University provides a supportive learning environment that allows students to develop personally and professionally.\n",
            "\n",
            "**Analysis:**\n",
            "\n",
            "* The cost of attending university is higher than gaining work experience first, but the potential benefits of increased earning potential and networking opportunities outweigh the costs.\n",
            "* The ROI of attending university is higher, with potential salary gains of up to 10% per year.\n",
            "\n",
            "**Implementation Plan:**\n",
            "\n",
            "1. Research and gather information on the costs and benefits of attending university versus gaining work experience first.\n",
            "2. Evaluate the ROI of attending university and gaining work experience first.\n",
            "3. Consider the implications of each option and potential challenges.\n",
            "4. Make a decision based on the analysis.\n",
            "5. Implement the chosen option and monitor the outcomes.\n",
            "\n",
            "By attending university immediately after undergraduate studies, individuals can gain valuable skills, increase their earning potential, and access career opportunities. This decision will lead to a successful career and personal growth, making it the recommended outcome.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Problem: For a city with traffic congestion, should they invest in expanding roads or improving public transportation?\n",
            "\n",
            "Initial Thoughts:\n",
            "1. assistant Here are three different initial thoughts or approaches to solve the problem of traffic congestion in a city: (Score: 5)\n",
            "\n",
            "2. 1. **Economic Perspective:** Investing in expanding roads could provide short-term relief by increasing the capacity of existing roads, reducing congestion and improving travel times for drivers. However, this approach may not address the underlying causes of traffic congestion, such as population growth, urban sprawl, and lack of public transportation. In the long run, increasing road capacity can lead to increased emissions, traffic accidents, and increased urban sprawl, ultimately exacerbating the problem. Therefore, this approach may not be the most sustainable solution. (Score: 5)\n",
            "\n",
            "3. 2. **Social Perspective:** Improving public transportation can provide a more sustainable and equitable solution to traffic congestion. By investing in expanding public transportation, the city can reduce the number of cars on the road, decrease congestion, and promote a healthier and more environmentally friendly lifestyle. This approach can also benefit the economy by reducing transportation costs, creating jobs, and increasing property values. However, implementing public transportation may require significant investment, infrastructure development, and user education, which can be challenging to manage. (Score: 4)\n",
            "\n",
            "Best Thought Selected: assistant Here are three different initial thoughts or approaches to solve the problem of traffic congestion in a city:\n",
            "\n",
            "Final Answer: assistant\n",
            "\n",
            "**Final Answer:**\n",
            "\n",
            "Based on the analysis, I recommend investing in expanding roads to improve traffic infrastructure. While there are high upfront costs and complexities associated with road expansion, the potential benefits of reduced traffic congestion, improved air quality, and increased economic activity outweigh these costs.\n",
            "\n",
            "**Recommendation:**\n",
            "\n",
            "Implement congestion pricing in high-traffic areas, invest in smart traffic management systems, and encourage alternative modes of transportation through incentives and infrastructure investments. Monitor and evaluate the effectiveness of these measures, and adjust the plan as needed to address emerging challenges and opportunities.\n",
            "\n",
            "**Implementation Plan:**\n",
            "\n",
            "1. Conduct a thorough feasibility study to identify high-traffic areas for congestion pricing and smart traffic management.\n",
            "2. Develop a congestion pricing plan, including the implementation schedule, costs, and benefits.\n",
            "3. Invest in smart traffic management systems, including ITS, traffic signal control systems, and real-time traffic data analytics.\n",
            "4. Implement congestion pricing and smart traffic management in high-traffic areas, starting with a small pilot project to test the effectiveness of the plan.\n",
            "5. Monitor traffic flow and congestion levels, and adjust the plan as needed to address emerging challenges and opportunities.\n",
            "6. Encourage alternative modes of transportation through incentives, such as public transportation subsidies, bike-sharing programs, and car-sharing services.\n",
            "7. Continuously evaluate the effectiveness of the plan, and make adjustments to optimize traffic flow and reduce congestion.\n",
            "\n",
            "**Timeline:**\n",
            "\n",
            "* Feasibility study: 6 months\n",
            "* Congestion pricing plan development: 12 months\n",
            "* Implementation: 2 years\n",
            "* Evaluation and adjustments: Ongoing\n",
            "\n",
            "**Budget:**\n",
            "\n",
            "* Initial investment: $500 million - $1 billion\n",
            "* Annual maintenance and operation costs: $200 million - $500 million\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "Expanding roads is a viable and effective solution to reduce traffic congestion, improve air quality, and increase economic activity. While there are challenges associated with the high upfront costs and complexities of road expansion, the potential benefits of a comprehensive plan should outweigh these costs.\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def create_tot_summary(tot_result):\n",
        "    \"\"\"\n",
        "    Create a summary of the Tree of Thoughts process for a problem.\n",
        "\n",
        "    Args:\n",
        "        tot_result (dict): Result from tot_solve\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted summary\n",
        "    \"\"\"\n",
        "    problem = tot_result[\"problem\"]\n",
        "    thoughts = tot_result[\"initial_thoughts\"]\n",
        "    evaluations = tot_result[\"evaluations\"]\n",
        "    best_thought = tot_result[\"best_thought\"]\n",
        "    final_answer = tot_result[\"final_answer\"]\n",
        "\n",
        "    summary = f\"Problem: {problem}\\n\\n\"\n",
        "    summary += \"Initial Thoughts:\\n\"\n",
        "\n",
        "    for i, thought in enumerate(thoughts):\n",
        "        # Find the evaluation for this thought\n",
        "        eval_score = \"N/A\"\n",
        "        for eval_result in evaluations:\n",
        "            if eval_result[\"thought\"] == thought:\n",
        "                eval_score = eval_result[\"score\"]\n",
        "                break\n",
        "\n",
        "        summary += f\"{i+1}. {thought} (Score: {eval_score})\\n\\n\"\n",
        "\n",
        "    summary += f\"Best Thought Selected: {best_thought}\\n\\n\"\n",
        "    summary += f\"Final Answer: {final_answer}\\n\"\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "# Create and display summaries for each problem\n",
        "for result in tot_results:\n",
        "    summary = create_tot_summary(result)\n",
        "    print(summary)\n",
        "    print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghTmafV120z_"
      },
      "source": [
        "## Comparing Prompting Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTtSaD7t2-LJ"
      },
      "source": [
        "Evaluation Framework Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dYN-tFbj2zqX"
      },
      "outputs": [],
      "source": [
        "class PromptTechnique:\n",
        "    \"\"\"Base class for prompt techniques.\"\"\"\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def generate_prompt(self, task):\n",
        "        \"\"\"Generate a prompt for the given task.\"\"\"\n",
        "        return task\n",
        "\n",
        "    def execute(self, task):\n",
        "        \"\"\"Execute the technique on a task and return the response.\"\"\"\n",
        "        prompt = self.generate_prompt(task)\n",
        "        return query_llm(prompt)\n",
        "\n",
        "\n",
        "class StandardPrompt(PromptTechnique):\n",
        "    \"\"\"Standard prompting without any special technique.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Standard\")\n",
        "\n",
        "\n",
        "class ZeroShotPrompt(PromptTechnique):\n",
        "    \"\"\"Zero-shot prompting with clear instructions.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Zero-shot\")\n",
        "\n",
        "    def generate_prompt(self, task):\n",
        "        return f\"Please respond to the following task: {task}\"\n",
        "\n",
        "\n",
        "class FewShotPrompt(PromptTechnique):\n",
        "    \"\"\"Few-shot prompting with examples.\"\"\"\n",
        "\n",
        "    def __init__(self, examples):\n",
        "        super().__init__(\"Few-shot\")\n",
        "        self.examples = examples\n",
        "\n",
        "    def generate_prompt(self, task):\n",
        "        prompt = \"Here are some examples:\\n\\n\"\n",
        "\n",
        "        for example in self.examples:\n",
        "            prompt += f\"Input: {example['input']}\\nOutput: {example['output']}\\n\\n\"\n",
        "\n",
        "        prompt += f\"Input: {task}\\nOutput:\"\n",
        "        return prompt\n",
        "\n",
        "\n",
        "class CoTPrompt(PromptTechnique):\n",
        "    \"\"\"Chain-of-Thought prompting.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Chain-of-Thought\")\n",
        "\n",
        "    def generate_prompt(self, task):\n",
        "        return f\"Think through this step by step: {task}\"\n",
        "\n",
        "\n",
        "class FewShotCoTPrompt(PromptTechnique):\n",
        "    \"\"\"Few-shot Chain-of-Thought prompting.\"\"\"\n",
        "\n",
        "    def __init__(self, examples):\n",
        "        super().__init__(\"Few-shot CoT\")\n",
        "        self.examples = examples\n",
        "\n",
        "    def generate_prompt(self, task):\n",
        "        prompt = \"I'll solve some problems step by step.\\n\\n\"\n",
        "\n",
        "        for example in self.examples:\n",
        "            prompt += f\"Problem: {example['input']}\\nSolution: {example['reasoning']}\\n\\n\"\n",
        "\n",
        "        prompt += f\"Problem: {task}\\nSolution:\"\n",
        "        return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga7iFsZw3bSf"
      },
      "source": [
        "Evaluation Tasks and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oXcGRUSZ3d1D"
      },
      "outputs": [],
      "source": [
        "# Define evaluation tasks by category\n",
        "evaluation_tasks = {\n",
        "    \"math_reasoning\": [\n",
        "        \"If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discount price, what is the final price?\",\n",
        "        \"A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\"\n",
        "    ],\n",
        "    \"common_sense\": [\n",
        "        \"If I put a few ice cubes in a glass of water at room temperature and leave it for 30 minutes, what will happen?\",\n",
        "        \"Why do cars have seat belts?\"\n",
        "    ],\n",
        "    \"creative_writing\": [\n",
        "        \"Write a short story about a robot that develops emotions.\",\n",
        "        \"Create a poem about autumn leaves.\"\n",
        "    ],\n",
        "    \"classification\": [\n",
        "        \"Classify this review as positive or negative: 'The food was delicious but the service was terrible.'\",\n",
        "        \"Determine if this statement is objective or subjective: 'The movie was released in 2022.'\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Define examples for few-shot techniques\n",
        "few_shot_examples = {\n",
        "    \"math_reasoning\": [\n",
        "        {\n",
        "            \"input\": \"If John has 5 apples and gives 2 to Mary, how many does he have left?\",\n",
        "            \"output\": \"3 apples\",\n",
        "            \"reasoning\": \"John starts with 5 apples. He gives 2 apples to Mary. So, John has 5 - 2 = 3 apples left.\"\n",
        "        },\n",
        "        {\n",
        "            \"input\": \"A rectangle has a length of 10 cm and a width of 5 cm. What is its area?\",\n",
        "            \"output\": \"50 square cm\",\n",
        "            \"reasoning\": \"The area of a rectangle is calculated by multiplying length × width. So, the area is 10 cm * 5 cm = 50 square cm.\"\n",
        "        }\n",
        "    ],\n",
        "    \"common_sense\": [\n",
        "        {\n",
        "            \"input\": \"What happens if you drop a glass on a hard floor?\",\n",
        "            \"output\": \"The glass will likely break.\",\n",
        "            \"reasoning\": \"Glass is a brittle material. When dropped on a hard floor, the impact force exceeds the material's strength, causing it to break.\"\n",
        "        },\n",
        "        {\n",
        "            \"input\": \"Why do plants need sunlight?\",\n",
        "            \"output\": \"Plants need sunlight for photosynthesis.\",\n",
        "            \"reasoning\": \"Plants use sunlight in the process of photosynthesis. They convert light energy from the sun into chemical energy for growth.\"\n",
        "        }\n",
        "    ],\n",
        "    \"creative_writing\": [\n",
        "        {\n",
        "            \"input\": \"Write a short story about a lost dog.\",\n",
        "            \"output\": \"Max wagged his tail as he chased the squirrel into the woods. Only when it disappeared up a tree did he realize he was lost...\",\n",
        "            \"reasoning\": \"The story begins with a dog chasing a squirrel, leading to a conflict where the dog gets lost. The middle includes his search, and the end has him finding his way home.\"\n",
        "        }\n",
        "    ],\n",
        "    \"classification\": [\n",
        "        {\n",
        "            \"input\": \"Classify this review as positive or negative: 'The movie was fantastic and I enjoyed every minute.'\",\n",
        "            \"output\": \"Positive\",\n",
        "            \"reasoning\": \"This review contains positive words like 'fantastic' and states that the reviewer 'enjoyed every minute.'\"\n",
        "        },\n",
        "        {\n",
        "            \"input\": \"Classify this review as positive or negative: 'The hotel room was dirty and the staff was rude.'\",\n",
        "            \"output\": \"Negative\",\n",
        "            \"reasoning\": \"This review contains negative descriptions: 'dirty' room and 'rude' staff.\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "def evaluate_responses(task_category, responses, ground_truth=None):\n",
        "    \"\"\"\n",
        "    Evaluate responses for a given task category.\n",
        "\n",
        "    Args:\n",
        "        task_category (str): Category of the task\n",
        "        responses (dict): Dictionary of technique name to response\n",
        "        ground_truth (list, optional): List of correct answers if available\n",
        "\n",
        "    Returns:\n",
        "        dict: Evaluation metrics\n",
        "    \"\"\"\n",
        "    # Define category-specific metrics\n",
        "    metrics = {\n",
        "        \"response_length\": {name: len(response.split()) for name, response in responses.items()}\n",
        "    }\n",
        "\n",
        "    # For math reasoning, we could try to extract numerical answers\n",
        "    if task_category == \"math_reasoning\":\n",
        "        import re\n",
        "\n",
        "        def extract_number(text):\n",
        "            # Try to find numerical answers with optional dollar signs\n",
        "            matches = re.findall(r'(\\$?\\d+\\.?\\d*)', text)\n",
        "            if matches:\n",
        "                return matches[-1]  # Return the last number found\n",
        "            return None\n",
        "\n",
        "        numeric_answers = {name: extract_number(response) for name, response in responses.items()}\n",
        "        metrics[\"extracted_answers\"] = numeric_answers\n",
        "\n",
        "    # Ask LLM to evaluate response quality\n",
        "    prompt = f\"\"\"\n",
        "    Evaluate the quality of the following responses to this task:\n",
        "    Task: {task_category}\n",
        "    \"\"\"\n",
        "\n",
        "    for name, response in responses.items():\n",
        "        if name != 'task':\n",
        "            prompt += f\"\\nResponse from {name} technique:\\n{response}\\n\"\n",
        "\n",
        "    prompt += \"\"\"\n",
        "    Please rate each response on a scale of 1-10 for the following criteria:\n",
        "    1. Correctness/Accuracy\n",
        "    2. Clarity and coherence\n",
        "    3. Completeness\n",
        "    4. Relevance to the task\n",
        "    Provide numerical ratings and brief explanations for each technique.\n",
        "    \"\"\"\n",
        "\n",
        "    # Assuming query_llm is a function that sends the prompt to an LLM and gets the evaluation back\n",
        "    evaluation = query_llm(prompt, max_new_tokens=1000)\n",
        "    metrics[\"llm_evaluation\"] = evaluation\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH37N_hI3vrj"
      },
      "source": [
        "Running the Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpgc437L3v3l",
        "outputId": "1b52ee21-783c-47fe-d7ae-f191ff631b45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating task: If a shirt originally costs $100 and is on sale fo...\n",
            "  Running Standard...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running Zero-shot...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running Chain-of-Thought...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running Few-shot...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running Few-shot CoT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating task: A train travels at a speed of 60 miles per hour. H...\n",
            "  Running Standard...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running Zero-shot...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running Chain-of-Thought...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running Few-shot...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running Few-shot CoT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Task: If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discount price, what is the final price?\n",
            "\n",
            "LLM Evaluation:\n",
            "assistant\n",
            "\n",
            "**Standard Technique Rating: 4/10**\n",
            "\n",
            "The standard technique provides a straightforward and logical approach to solving the task. It correctly calculates the discount amount and then applies the additional discount. However, the technique lacks clarity and coherence by not clearly explaining the steps or the logical connection between the discount calculation and the final price calculation. Additionally, the response does not address the original price, making it less relevant to the task.\n",
            "\n",
            "**Few-shot Technique Rating: 2/10**\n",
            "\n",
            "The few-shot technique is a simplistic approach that does not provide a clear understanding of the mathematical concepts involved. It calculates the discount amount and then applies the additional discount, but fails to explain the underlying math or provide any logical reasoning. The response lacks clarity and coherence, and the final price is not accurately calculated.\n",
            "\n",
            "**Chain-of-Thought Technique Rating: 6/10**\n",
            "\n",
            "The chain-of-thought technique provides a clear step-by-step approach to solving the task. It logically connects the discount calculation to the final price calculation, but the response does not fully explain the math or provide any logical reasoning. The final price is still not accurately calculated, and the response lacks clarity and coherence.\n",
            "\n",
            "**Zero-shot Technique Rating: 1/10**\n",
            "\n",
            "The zero-shot technique provides no mathematical reasoning or logical explanation for the calculation. The response simply states the final price without providing any evidence or justification for the answer. This approach is not only inaccurate but also fails to address the original task.\n",
            "\n",
            "Response Lengths:\n",
            "  task: 29 words\n",
            "  Standard: 85 words\n",
            "  Zero-shot: 95 words\n",
            "  Chain-of-Thought: 59 words\n",
            "  Few-shot: 74 words\n",
            "  Few-shot CoT: 77 words\n",
            "\n",
            "Task: A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\n",
            "\n",
            "LLM Evaluation:\n",
            "assistant\n",
            "\n",
            "Here are the ratings for each response:\n",
            "\n",
            "**Standard Technique: 6/10**\n",
            "\n",
            "The response is correct in terms of mathematical accuracy, but it lacks clarity and coherence. It simply states the same calculation multiple times without explaining the underlying reasoning. The language is also somewhat awkward, making it difficult to follow. For example, the phrase \"we need to multiply the speed of the train by the time traveled\" is a vague statement that doesn't provide any context.\n",
            "\n",
            "**Zero-shot Technique: 7/10**\n",
            "\n",
            "The response is similar in structure to the standard technique, with some minor improvements. However, the language is still somewhat awkward, and the explanation of the calculation is brief and unclear. The phrase \"to find the distance traveled by the train\" is a bit vague, and the sentence \"we need to multiply the speed of the train (60 miles per hour) by the time it travels (2.5 hours)\" could be rephrased to make it clearer. Overall, the response is clear in terms of mathematical accuracy, but could benefit from a bit more clarity and coherence.\n",
            "\n",
            "**Chain-of-Thought Technique: 8/10**\n",
            "\n",
            "The response is a bit more coherent and clear than the standard technique, but still lacks a clear explanation of the underlying reasoning. The language is a bit more concise, but some of the phrases are still a bit awkward. The sentence \"Distance = Speed x Time\" is a clear and concise statement that effectively conveys the solution. However, the explanation of the calculation could be a bit more detailed, such as explaining that the formula for distance is Distance = Speed x Time, and then providing a brief explanation of why this formula is used.\n",
            "\n",
            "**Few-shot Technique: 8/10**\n",
            "\n",
            "The response is a good example of a few-shot technique, as it uses a single example (the train traveling 150 miles in 2.5 hours) to solve a problem. The language is clear and concise, and the explanation of the calculation is easy to follow. However, the response could benefit from a bit more generalization and abstraction, as it relies on a specific example to provide a solution.\n",
            "\n",
            "**Relevance to the task: 6/10**\n",
            "\n",
            "The responses are all relevant to the task of finding the distance traveled by a train, but they all use the same calculation. While this is a useful technique, it's not particularly innovative or insightful, and doesn't provide much new information beyond what's already known about the task.\n",
            "\n",
            "Overall, the responses could benefit from more clarity, coherence, and originality. However, they all have some value as examples of how to approach the task.\n",
            "\n",
            "Response Lengths:\n",
            "  task: 19 words\n",
            "  Standard: 57 words\n",
            "  Zero-shot: 53 words\n",
            "  Chain-of-Thought: 50 words\n",
            "  Few-shot: 62 words\n",
            "  Few-shot CoT: 49 words\n"
          ]
        }
      ],
      "source": [
        "def run_evaluation(task_category, techniques):\n",
        "    \"\"\"\n",
        "    Run evaluation for a specific task category using multiple techniques.\n",
        "\n",
        "    Args:\n",
        "        task_category (str): Category of tasks to evaluate\n",
        "        techniques (list): List of PromptTechnique instances\n",
        "\n",
        "    Returns:\n",
        "        list: Evaluation results\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Iterate over tasks in the evaluation_tasks for the given category\n",
        "    for task in evaluation_tasks[task_category]:\n",
        "        print(f\"\\nEvaluating task: {task[:50]}...\")\n",
        "\n",
        "        # Get responses from all techniques\n",
        "        task_responses = {\"task\": task}\n",
        "        for technique in techniques:\n",
        "            print(f\"  Running {technique.name}...\")\n",
        "            response = technique.execute(task)\n",
        "            task_responses[technique.name] = response\n",
        "\n",
        "        # Evaluate the responses\n",
        "        metrics = evaluate_responses(task_category, task_responses)\n",
        "\n",
        "        # Store the results\n",
        "        results.append({\n",
        "            \"task\": task,\n",
        "            \"responses\": task_responses,\n",
        "            \"metrics\": metrics\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set up techniques for evaluation\n",
        "standard = StandardPrompt()\n",
        "zero_shot = ZeroShotPrompt()\n",
        "cot = CoTPrompt()\n",
        "\n",
        "# Evaluate a specific category\n",
        "category = \"math_reasoning\"\n",
        "few_shot = FewShotPrompt(few_shot_examples[category])\n",
        "few_shot_cot = FewShotCoTPrompt(few_shot_examples[category])\n",
        "\n",
        "# List of techniques to be evaluated\n",
        "techniques = [standard, zero_shot, cot, few_shot, few_shot_cot]\n",
        "\n",
        "# Run the evaluation\n",
        "evaluation_results = run_evaluation(category, techniques)\n",
        "\n",
        "# Display results\n",
        "for result in evaluation_results:\n",
        "    print(f\"\\nTask: {result['task']}\")\n",
        "    print(\"\\nLLM Evaluation:\")\n",
        "    print(result['metrics']['llm_evaluation'])\n",
        "\n",
        "    print(\"\\nResponse Lengths:\")\n",
        "    for technique, length in result['metrics']['response_length'].items():\n",
        "        print(f\"  {technique}: {length} words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjKM-iUE4ax2"
      },
      "source": [
        "Visualizing the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "flU-JGRH4YMT",
        "outputId": "b9118189-1197-4195-92bb-19058f91d299"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def extract_scores_from_evaluation(evaluation_text):\n",
        "    \"\"\"\n",
        "    Extract numerical scores from LLM evaluation text.\n",
        "    This is a simplified implementation and might need refinement.\n",
        "\n",
        "    Args:\n",
        "        evaluation_text (str): Text containing evaluations\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of technique to scores\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    # Define the techniques we're looking for\n",
        "    technique_names = [\"Standard\", \"Zero-shot\", \"Chain-of-Thought\", \"Few-shot\", \"Few-shot CoT\"]\n",
        "\n",
        "    # Initialize results\n",
        "    scores = {technique: {} for technique in technique_names}\n",
        "\n",
        "    # Look for patterns like \"Technique: X/10\" or \"Technique - X/10\"\n",
        "    for technique in technique_names:\n",
        "        # Find all instances where the technique name is followed by numbers\n",
        "        pattern = fr'{technique}[^0-9]*(\\d+)(?:/10)?'\n",
        "        matches = re.findall(pattern, evaluation_text)\n",
        "\n",
        "        if matches:\n",
        "            # Assume first match is for correctness, second for clarity, etc.\n",
        "            criteria = [\"Correctness\", \"Clarity\", \"Completeness\", \"Relevance\"]\n",
        "            for i, score in enumerate(matches[:len(criteria)]):\n",
        "                try:\n",
        "                    scores[technique][criteria[i]] = int(score)\n",
        "                except ValueError:\n",
        "                    scores[technique][criteria[i]] = 0\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "def plot_evaluation_results(evaluation_results):\n",
        "    \"\"\"\n",
        "    Plot evaluation results for visual comparison.\n",
        "\n",
        "    Args:\n",
        "        evaluation_results (list): Results from run_evaluation\n",
        "\n",
        "    Returns:\n",
        "        None (displays plots)\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    # Extract scores for each task\n",
        "    all_scores = []\n",
        "    technique_names = []\n",
        "\n",
        "    for result in evaluation_results:\n",
        "        llm_eval = result['metrics']['llm_evaluation']\n",
        "        scores = extract_scores_from_evaluation(llm_eval)\n",
        "        all_scores.append(scores)\n",
        "\n",
        "        # Get technique names if not already set\n",
        "        if not technique_names and scores:\n",
        "            technique_names = list(scores.keys())\n",
        "\n",
        "    # Aggregate scores across tasks\n",
        "    agg_scores = {technique: {criterion: [] for criterion in [\"Correctness\", \"Clarity\", \"Completeness\", \"Relevance\"]}\n",
        "                  for technique in technique_names}\n",
        "\n",
        "    for scores in all_scores:\n",
        "        for technique in technique_names:\n",
        "            if technique in scores:\n",
        "                for criterion, score in scores[technique].items():\n",
        "                    agg_scores[technique][criterion].append(score)\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_scores = {technique: {criterion: np.mean(scores) if scores else 0\n",
        "                              for criterion, scores in criteria_scores.items()}\n",
        "                  for technique, criteria_scores in agg_scores.items()}\n",
        "\n",
        "    # Plot the results\n",
        "    criteria = [\"Correctness\", \"Clarity\", \"Completeness\", \"Relevance\"]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    x = np.arange(len(criteria))\n",
        "    width = 0.15\n",
        "    multiplier = 0\n",
        "\n",
        "    for technique, scores in avg_scores.items():\n",
        "        offset = width * multiplier\n",
        "        values = [scores.get(criterion, 0) for criterion in criteria]\n",
        "        ax.bar(x + offset, values, width, label=technique)\n",
        "        multiplier += 1\n",
        "\n",
        "    ax.set_xlabel('Criteria')\n",
        "    ax.set_ylabel('Average Score (1-10)')\n",
        "    ax.set_title('Comparison of Prompting Techniques')\n",
        "    ax.set_xticks(x + width * (len(avg_scores) - 1) / 2)\n",
        "    ax.set_xticklabels(criteria)\n",
        "    ax.legend(loc='best')\n",
        "    ax.set_ylim(0, 10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # You can also save the figure\n",
        "    plt.savefig('prompting_techniques_comparison.png')\n",
        "\n",
        "# Plot the results\n",
        "plot_evaluation_results(evaluation_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01969153bc1b4018b333997345ca2e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f4a3c9298904434a1ca68943d44502c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ff044cc4a84432f8d57bd227e5083ec",
              "IPY_MODEL_7ba204cf9f5f4c5e8881bdb1e84a3821",
              "IPY_MODEL_dbbcb2fa585a49aeb00f715df6c18656"
            ],
            "layout": "IPY_MODEL_523581123fe5476cb2bbb9cfc3bd913e"
          }
        },
        "14878143963149558febbbe901d6f7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16b41f2d71414d26b211d178bc37aabf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a596debcb54e07993b0f883a1f7176": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423706f4620c40849aa8fab4c1dc045a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4951bb19b25f456c82e49c07054a3773": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "523581123fe5476cb2bbb9cfc3bd913e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff044cc4a84432f8d57bd227e5083ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d5fd1455b194e7da1d3bc19732d0dc8",
            "placeholder": "​",
            "style": "IPY_MODEL_14878143963149558febbbe901d6f7ed",
            "value": "generation_config.json: 100%"
          }
        },
        "6e6ae9cdbbcd424986c18c02d8ff875e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73bad045d37542d7828dfa95e9268105",
              "IPY_MODEL_dca1a7c18fb3419697c443e45ffce1bd",
              "IPY_MODEL_ab261544262e4ce899a5ef5b51f09590"
            ],
            "layout": "IPY_MODEL_b650883cf03f402092b8110d6856f9a0"
          }
        },
        "73bad045d37542d7828dfa95e9268105": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_423706f4620c40849aa8fab4c1dc045a",
            "placeholder": "​",
            "style": "IPY_MODEL_e0163877db2540f5b0564174a3f121d6",
            "value": "model.safetensors: 100%"
          }
        },
        "7ba204cf9f5f4c5e8881bdb1e84a3821": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26a596debcb54e07993b0f883a1f7176",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb85762a102149369e19cfea1b8c9ce0",
            "value": 189
          }
        },
        "82e69219534e45dfb846ba47c4429274": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba2d1c3ba8a487bb17be9714daa693c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d5fd1455b194e7da1d3bc19732d0dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab261544262e4ce899a5ef5b51f09590": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e69219534e45dfb846ba47c4429274",
            "placeholder": "​",
            "style": "IPY_MODEL_4951bb19b25f456c82e49c07054a3773",
            "value": " 2.47G/2.47G [00:30&lt;00:00, 54.8MB/s]"
          }
        },
        "b650883cf03f402092b8110d6856f9a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2a9c4b795f4c9a95186e4edc96e4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbcb2fa585a49aeb00f715df6c18656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da2a9c4b795f4c9a95186e4edc96e4b2",
            "placeholder": "​",
            "style": "IPY_MODEL_01969153bc1b4018b333997345ca2e77",
            "value": " 189/189 [00:00&lt;00:00, 19.5kB/s]"
          }
        },
        "dca1a7c18fb3419697c443e45ffce1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b41f2d71414d26b211d178bc37aabf",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ba2d1c3ba8a487bb17be9714daa693c",
            "value": 2471645608
          }
        },
        "e0163877db2540f5b0564174a3f121d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb85762a102149369e19cfea1b8c9ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
